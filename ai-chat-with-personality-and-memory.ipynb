{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Use Case: Chat with memory and personality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "groq_api_key = os.environ[\"GROQ_API_KEY\"]\n",
    "langchain_key = os.environ[\"LANGCHAIN_API_KEY\"] \n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup LLM to use, llama3 using Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama3-8b-8192\",\n",
    "    temperature=0, # no hallucination \n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    verbose=True\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "\n",
    "def get_session_history(session_id):\n",
    "    return SQLChatMessageHistory(session_id, \"sqlite:///memory.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You're an assistant who speaks in {language}. Respond in 20 words or fewer\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "runnable = prompt | llm | StrOutputParser()\n",
    "\n",
    "runnable_with_history = RunnableWithMessageHistory(\n",
    "    runnable,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: ValueError()\n",
      "Error in callback coroutine: ValueError()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'¡Hola Luis! ¡No te preocupes, ya sabes la respuesta! El edificio más alto de México es el Torre Latinoamericana, que mide 182 metros de altura.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable_with_history.invoke(\n",
    "    {'language': 'spanish', 'input':'Hi I am Luis, I am 30 years old, I want to ask you how tall are mexicos most tall building'}\n",
    "    ,\n",
    "    config={\"configurable\": {\"user_id\": \"456\", \"session_id\": \"1\"}}\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: ValueError()\n",
      "Error in callback coroutine: ValueError()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'¡No te preocupes, Luis!'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable_with_history.invoke(\n",
    "    {'language': 'spanish', 'input':'I forgot my name, whats my name'}\n",
    "    ,\n",
    "    config={\"configurable\": {\"user_id\": \"456\", \"session_id\": \"1\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: ValueError()\n",
      "Error in callback coroutine: ValueError()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'¡Ah! Preguntaste sobre el edificio más alto de México y también te preguntaste qué era tu nombre.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable_with_history.invoke(\n",
    "    {'language': 'spanish', 'input':'what I asked before?'}\n",
    "    ,\n",
    "    config={\"configurable\": {\"user_id\": \"456\", \"session_id\": \"1\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: ValueError()\n",
      "Error in callback coroutine: ValueError()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'¡Tú tienes 30 años, Luis!'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable_with_history.invoke(\n",
    "    {'language': 'spanish', 'input':'how old am I?'}\n",
    "    ,\n",
    "    config={\"configurable\": {\"user_id\": \"456\", \"session_id\": \"1\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-rag-document-qa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
